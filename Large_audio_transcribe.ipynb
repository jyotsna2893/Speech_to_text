{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-02T07:40:58.044561Z","iopub.execute_input":"2021-08-02T07:40:58.04519Z","iopub.status.idle":"2021-08-02T07:40:58.07746Z","shell.execute_reply.started":"2021-08-02T07:40:58.045127Z","shell.execute_reply":"2021-08-02T07:40:58.07585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Relevant Libraries","metadata":{}},{"cell_type":"code","source":"import torch\n#import fairseq\nimport torchaudio\n#from fairseq.models.wav2vec import Wav2VecModel\nfrom pydub import AudioSegment\nimport os\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:25:36.037786Z","iopub.execute_input":"2021-08-02T11:25:36.038233Z","iopub.status.idle":"2021-08-02T11:25:37.458366Z","shell.execute_reply.started":"2021-08-02T11:25:36.03814Z","shell.execute_reply":"2021-08-02T11:25:37.457367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:25:41.96958Z","iopub.execute_input":"2021-08-02T11:25:41.969975Z","iopub.status.idle":"2021-08-02T11:25:42.029978Z","shell.execute_reply.started":"2021-08-02T11:25:41.969925Z","shell.execute_reply":"2021-08-02T11:25:42.028657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sound = AudioSegment.from_file('../input/audio-file/audio (1).wav', \"wav\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:25:46.789961Z","iopub.execute_input":"2021-08-02T11:25:46.790339Z","iopub.status.idle":"2021-08-02T11:25:47.973162Z","shell.execute_reply.started":"2021-08-02T11:25:46.790307Z","shell.execute_reply":"2021-08-02T11:25:47.972335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We are handling long audio files, so best way is to break it into smaller chunks. I am using Audiosegemnt class of Pydub library","metadata":{}},{"cell_type":"code","source":"t1 = 0\ncount = 0\n#tensor_list = []\nfolder = './'\nfor i in range((int(len(sound)/100)), int(len(sound)), (int(len(sound)/100))):\n    section = sound[t1:i]\n    filepath = folder + str(count+1) + '.wav'\n    section.export(filepath, format=\"wav\")\n    t1=i\n    count+=1","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:25:51.962615Z","iopub.execute_input":"2021-08-02T11:25:51.962928Z","iopub.status.idle":"2021-08-02T11:25:52.040961Z","shell.execute_reply.started":"2021-08-02T11:25:51.9629Z","shell.execute_reply":"2021-08-02T11:25:52.039989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Huggingface transformers wav2vec model","metadata":{}},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:25:58.007872Z","iopub.execute_input":"2021-08-02T11:25:58.008218Z","iopub.status.idle":"2021-08-02T11:26:02.590795Z","shell.execute_reply.started":"2021-08-02T11:25:58.008185Z","shell.execute_reply":"2021-08-02T11:26:02.589773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:26:05.520754Z","iopub.execute_input":"2021-08-02T11:26:05.521114Z","iopub.status.idle":"2021-08-02T11:26:29.149715Z","shell.execute_reply.started":"2021-08-02T11:26:05.521081Z","shell.execute_reply":"2021-08-02T11:26:29.148891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:27:12.920858Z","iopub.execute_input":"2021-08-02T11:27:12.921212Z","iopub.status.idle":"2021-08-02T11:27:18.488185Z","shell.execute_reply.started":"2021-08-02T11:27:12.921179Z","shell.execute_reply":"2021-08-02T11:27:18.487409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder = './'\nfile_list = os.listdir(folder)\nfile_list.remove('__notebook_source__.ipynb')","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:27:26.892615Z","iopub.execute_input":"2021-08-02T11:27:26.893032Z","iopub.status.idle":"2021-08-02T11:27:26.900541Z","shell.execute_reply.started":"2021-08-02T11:27:26.892987Z","shell.execute_reply":"2021-08-02T11:27:26.899694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transcribe(audio_file_list, processor,device,model):\n    text_list = []\n    for file in audio_file_list:\n        path = './'+ file\n        input_values = processor(torchaudio.load(path)[0],sampling_rate=16000, padding=True, return_tensors = \"pt\").input_values\n        input_values = input_values.squeeze().to(device)\n        logits = model(input_values).logits\n        predicted_ids = torch.argmax(logits, dim=-1)\n        transcription = processor.decode(predicted_ids[0])\n        text_list.append(transcription)\n    return ' '.join(text_list)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:27:30.076448Z","iopub.execute_input":"2021-08-02T11:27:30.076775Z","iopub.status.idle":"2021-08-02T11:27:30.082893Z","shell.execute_reply.started":"2021-08-02T11:27:30.076738Z","shell.execute_reply":"2021-08-02T11:27:30.081814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transcribe(file_list, processor, device, model)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T11:27:32.985629Z","iopub.execute_input":"2021-08-02T11:27:32.985948Z","iopub.status.idle":"2021-08-02T11:27:45.75856Z","shell.execute_reply.started":"2021-08-02T11:27:32.985917Z","shell.execute_reply":"2021-08-02T11:27:45.757567Z"},"trusted":true},"execution_count":null,"outputs":[]}]}